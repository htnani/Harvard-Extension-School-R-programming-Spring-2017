install.packages(leaps)
install.packages("leaps")
install.packages("glmnet")
CPUDatRaw <- read.table("machine.data",sep=",")
names(CPUDatRaw) <- c("vendor name","model name","MYCT","MMIN","MMAX","CACH","CHMIN","CHMAX","PRP","ERP")
regColnames <- names(CPUDatRaw)[!(names(CPUDatRaw) %in% c("vendor name","model name","ERP"))]
## Discard irrelevant columns
CPUDat <- CPUDatRaw[regColnames]
## Log-transform everything
CPUDat <- log(CPUDat+1)
summaryMetrics <- NULL
whichAll <- list()
rsRes <- regsubsets(PRP~.,CPUDat,method="exhaustive",nvmax=6)
library(ISLR)
library(leaps)
library(ggplot2)
library(glmnet)
rsRes <- regsubsets(PRP~.,CPUDat,method="exhaustive",nvmax=6)
bTrain <- sample(rep(c(TRUE,FALSE),length.out=nrow(CPUDat)))
rsTrain <- regsubsets(PRP~.,CPUDat[bTrain,],nvmax=6,method="exhaustive")
summary(rsTrain)$which
traceback()
dfTmp <- NULL
whichSum <- array(0,dim=c(6,7,4),
dimnames=list(NULL,colnames(model.matrix(PRP~.,CPUDat)),
c("exhaustive", "backward", "forward", "seqrep")))
# Split data into training and test 30 times:
iFolds <- 10
for ( iFold in 1:iFolds ) {
bTrain <- sample(1:iFolds, nrow(CPUDat), replace = TRUE)
# Try each method available in regsubsets
# to select best model of each size:
for ( jSelect in c("exhaustive", "backward", "forward", "seqrep") ) {
rsTrain <- regsubsets(PRP~.,CPUDat[bTrain != iFold,],nvmax=6,method=jSelect)
# Add up variable selections:
whichSum[,,jSelect] <- whichSum[,,jSelect] + summary(rsTrain)$which
# Calculate test error for each set of variables
# using predict.regsubsets implemented above:
for ( kVarSet in 1:6 ) {
# make predictions:
testPred <- predict(rsTrain,CPUDat[bTrain == iFold,],id=kVarSet)
# calculate MSE:
mseTest <- mean((testPred-CPUDat[bTrain == iFold,"PRP"])^2)
mseTrain <- summary(rsTrain)$rss[kVarSet]/length(CPUDat[bTrain != iFold])
# add to data.frame for future plotting:
##dfTmp <- rbind(dfTmp,data.frame(fold=iFold,sel=jSelect,vars=kVarSet,
## TESTING DATAFRAME WITH FEWER COLUMNS
## mse=c(mseTest,mseTrain), trainTest=c("test (in fold)","train (out of fold)")))
dfTmp <- rbind(dfTmp,data.frame(sel=jSelect,vars=kVarSet))
}
}
}
predict.regsubsets <- function (object, newdata, id, ...){
form=as.formula(object$call [[2]])
mat=model.matrix(form,newdata)
coefi=coef(object,id=id)
xvars=names (coefi)
mat[,xvars] %*% coefi
}
dfTmp <- NULL
whichSum <- array(0,dim=c(6,7,4),
dimnames=list(NULL,colnames(model.matrix(PRP~.,CPUDat)),
c("exhaustive", "backward", "forward", "seqrep")))
# Split data into training and test 30 times:
iFolds <- 10
for ( iFold in 1:iFolds ) {
bTrain <- sample(1:iFolds, nrow(CPUDat), replace = TRUE)
# Try each method available in regsubsets
# to select best model of each size:
for ( jSelect in c("exhaustive", "backward", "forward", "seqrep") ) {
rsTrain <- regsubsets(PRP~.,CPUDat[bTrain != iFold,],nvmax=6,method=jSelect)
# Add up variable selections:
whichSum[,,jSelect] <- whichSum[,,jSelect] + summary(rsTrain)$which
# Calculate test error for each set of variables
# using predict.regsubsets implemented above:
for ( kVarSet in 1:6 ) {
# make predictions:
testPred <- predict(rsTrain,CPUDat[bTrain == iFold,],id=kVarSet)
# calculate MSE:
mseTest <- mean((testPred-CPUDat[bTrain == iFold,"PRP"])^2)
mseTrain <- summary(rsTrain)$rss[kVarSet]/length(CPUDat[bTrain != iFold])
# add to data.frame for future plotting:
##dfTmp <- rbind(dfTmp,data.frame(fold=iFold,sel=jSelect,vars=kVarSet,
## TESTING DATAFRAME WITH FEWER COLUMNS
## mse=c(mseTest,mseTrain), trainTest=c("test (in fold)","train (out of fold)")))
dfTmp <- rbind(dfTmp,data.frame(sel=jSelect,vars=kVarSet))
}
}
}
dfTmp <- NULL
whichSum <- array(0,dim=c(6,7,4),
dimnames=list(NULL,colnames(model.matrix(PRP~.,CPUDat)),
c("exhaustive", "backward", "forward", "seqrep")))
# Split data into training and test 30 times:
iFolds <- 10
for ( iFold in 1:iFolds ) {
bTrain <- sample(1:iFolds, nrow(CPUDat), replace = TRUE)
# Try each method available in regsubsets
# to select best model of each size:
for ( jSelect in c("exhaustive", "backward", "forward", "seqrep") ) {
rsTrain <- regsubsets(PRP~.,CPUDat[(bTrain != iFold),],nvmax=6,method=jSelect)
# Add up variable selections:
whichSum[,,jSelect] <- whichSum[,,jSelect] + summary(rsTrain)$which
# Calculate test error for each set of variables
# using predict.regsubsets implemented above:
for ( kVarSet in 1:6 ) {
# make predictions:
testPred <- predict(rsTrain,CPUDat[(bTrain == iFold),],id=kVarSet)
# calculate MSE:
mseTest <- mean((testPred-CPUDat[(bTrain == iFold),"PRP"])^2)
mseTrain <- summary(rsTrain)$rss[kVarSet]/length(CPUDat[bTrain != iFold])
# add to data.frame for future plotting:
##dfTmp <- rbind(dfTmp,data.frame(fold=iFold,sel=jSelect,vars=kVarSet,
## TESTING DATAFRAME WITH FEWER COLUMNS
## mse=c(mseTest,mseTrain), trainTest=c("test (in fold)","train (out of fold)")))
dfTmp <- rbind(dfTmp,data.frame(sel=jSelect,vars=kVarSet))
}
}
}
traceback()
dfTmp <- NULL
whichSum <- array(0,dim=c(6,7,4),
dimnames=list(NULL,colnames(model.matrix(PRP~.,CPUDat)),
c("exhaustive", "backward", "forward", "seqrep")))
# Split data into training and test 30 times:
iFolds <- 10
bTrain <- sample(1:iFolds, nrow(CPUDat), replace = TRUE)
rsTrain <- regsubsets(PRP~.,CPUDat[bTrain != 1,],nvmax=6,method="exhaustive")
whichSum[,,"exhaustive"] <- whichSum[,,"exhaustive"] + summary(rsTrain)$which
testPred <- predict(rsTrain,CPUDat[bTrain == 1,],id=1)
mseTest <- mean((testPred-CPUDat[bTrain == 1,"PRP"])^2)
mseTrain <- summary(rsTrain)$rss[1]/length(CPUDat[bTrain != 1])
dfTmp <- NULL
whichSum <- array(0,dim=c(6,7,4),
dimnames=list(NULL,colnames(model.matrix(PRP~.,CPUDat)),
c("exhaustive", "backward", "forward", "seqrep")))
# Split data into training and test 30 times:
iFolds <- 10
for ( iFold in 1:iFolds ) {
bTrain <- sample(1:iFolds, nrow(CPUDat), replace = TRUE)
# Try each method available in regsubsets
# to select best model of each size:
for ( jSelect in c("exhaustive", "backward", "forward", "seqrep") ) {
rsTrain <- regsubsets(PRP~.,CPUDat[bTrain != iFold,],nvmax=6,method=jSelect)
# Add up variable selections:
whichSum[,,jSelect] <- whichSum[,,jSelect] + summary(rsTrain)$which
# Calculate test error for each set of variables
# using predict.regsubsets implemented above:
for ( kVarSet in 1:6 ) {
# make predictions:
testPred <- predict(rsTrain,CPUDat[bTrain == iFold,],id=kVarSet)
# calculate MSE:
mseTest <- mean((testPred-CPUDat[bTrain == iFold,"PRP"])^2)
mseTrain <- summary(rsTrain)$rss[kVarSet]/length(CPUDat[bTrain != iFold,])
# add to data.frame for future plotting:
##dfTmp <- rbind(dfTmp,data.frame(fold=iFold,sel=jSelect,vars=kVarSet,
## TESTING DATAFRAME WITH FEWER COLUMNS
## mse=c(mseTest,mseTrain), trainTest=c("test (in fold)","train (out of fold)")))
dfTmp <- rbind(dfTmp,data.frame(sel=jSelect,vars=kVarSet))
}
}
}
ggplot(dfTmp,aes(x=factor(vars),y=mse,colour=sel)) + geom_boxplot()+facet_wrap(~trainTest)
help("+.gg")
ggplot(dfTmp,aes(x=factor(vars),y=mse,colour=sel)) + geom_boxplot()
ggplot(dfTmp,aes(x=factor(vars),y=mse,colour=sel)) + geom_boxplot()+facet_wrap(~trainTest)
?facet_wrap
dfTmp <- NULL
whichSum <- array(0,dim=c(6,7,4),
dimnames=list(NULL,colnames(model.matrix(PRP~.,CPUDat)),
c("exhaustive", "backward", "forward", "seqrep")))
# Split data into training and test 30 times:
iFolds <- 10
for ( iFold in 1:iFolds ) {
bTrain <- sample(1:iFolds, nrow(CPUDat), replace = TRUE)
# Try each method available in regsubsets
# to select best model of each size:
for ( jSelect in c("exhaustive", "backward", "forward", "seqrep") ) {
rsTrain <- regsubsets(PRP~.,CPUDat[bTrain != iFold,],nvmax=6,method=jSelect)
# Add up variable selections:
whichSum[,,jSelect] <- whichSum[,,jSelect] + summary(rsTrain)$which
# Calculate test error for each set of variables
# using predict.regsubsets implemented above:
for ( kVarSet in 1:6 ) {
# make predictions:
testPred <- predict(rsTrain,CPUDat[bTrain == iFold,],id=kVarSet)
# calculate MSE:
mseTest <- mean((testPred-CPUDat[bTrain == iFold,"PRP"])^2)
mseTrain <- summary(rsTrain)$rss[kVarSet]/length(CPUDat[bTrain != iFold,])
# add to data.frame for future plotting:
dfTmp <- rbind(dfTmp,data.frame(fold=iFold,sel=jSelect,vars=kVarSet,
mse=c(mseTest,mseTrain), trainTest=c("test (in fold)","train (out of fold)")))
}
}
}
# plot MSEs by training/test, number of
# variables and selection method:
ggplot(dfTmp,aes(x=factor(vars),y=mse,colour=sel)) + geom_boxplot()+facet_wrap(~trainTest)
mse
sel
y
dfTmp$mse
mseTest
testPred
data.frame(testPred, CPUDat[bTrain == iFold, "PRP"])
rsTrain
form=as.formula(rsTrain$call [[2]])
mat=model.matrix(form,CPUDat[bTrain == iFold,])
coefi=coef(rsTrain,id=kVarSet)
xvars=names (coefi)
mat[,xvars] %*% coefi
}
coefi
?coef
coef(rsTrain)
coef(rsTrain, 6)
length(CPUDat)
length(CPUDat[bTrain != iFold])
length(CPUDat[bTrain != 1])
length(CPUDat[bTrain != 1,])
length(CPUDat[[bTrain != 1,]])
length(CPUDat[[bTrain != 1]])
nrows(CPUDat[bTrain != 1],)
nrow(CPUDat[bTrain != 1],)
nrow(CPUDat[bTrain != 1,])
mean(dfTMp$mse[vars = 3 && trainTest = "test"])
mean((CPUDat[!bTrain, "PRP"]-log(CPUDatRaw+1)[!bTrain, "ERP"]))
mean(dfTMp$mse[vars == 3 && trainTest == "test"])
mean((CPUDat[!bTrain, "PRP"]-log(CPUDatRaw[names(CPUDatRaw)[!(names(CPUDatRaw) %in% c("vendor name","model name","ERP"))]]+1)[!bTrain, "ERP"]))
mean(dfTMp$mse[vars == 3 && trainTest == "test"])
mean((CPUDat[!bTrain, "PRP"]-log(CPUDatRaw[names(CPUDatRaw)[!(names(CPUDatRaw) %in% c("vendor name","model name","ERP"))]]+1)[!bTrain, "ERP"]))
mean(dfTmp$mse[vars == 3 && trainTest == "test"])
mean((CPUDat[!bTrain, "PRP"]-log(CPUDatRaw[names(CPUDatRaw)[!(names(CPUDatRaw) %in% c("vendor name","model name","ERP"))]]+1)[!bTrain, "ERP"]))
mean(dfTMp$mse[dfTmp$vars == 3 && dfTmp$trainTest == "test"])
mean((CPUDat[!bTrain, "PRP"]-log(CPUDatRaw[names(CPUDatRaw)[!(names(CPUDatRaw) %in% c("vendor name","model name","ERP"))]]+1)[!bTrain, "ERP"]))
mean(dfTmp$mse[dfTmp$vars == 3 && dfTmp$trainTest == "test"])
mean((CPUDat[!bTrain, "PRP"]-log(CPUDatRaw[names(CPUDatRaw)[!(names(CPUDatRaw) %in% c("vendor name","model name","ERP"))]]+1)[!bTrain, "ERP"]))
dfTmp$mse[dfTmp$vars == 3 && dfTmp$trainTest == "test"]
dfTmp$vars == 3 && dfTmp$trainTest == "test"
dfTmp$vars == 3
dfTmp$trainTest == "test"
dfTmp$trainTest
mean(dfTmp$mse[dfTmp$vars == 3 && dfTmp$trainTest == "test "])
mean((CPUDat[!bTrain, "PRP"]-log(CPUDatRaw[names(CPUDatRaw)[!(names(CPUDatRaw) %in% c("vendor name","model name","ERP"))]]+1)[!bTrain, "ERP"]))
dfTmp <- NULL
whichSum <- array(0,dim=c(6,7,4),
dimnames=list(NULL,colnames(model.matrix(PRP~.,CPUDat)),
c("exhaustive", "backward", "forward", "seqrep")))
# Split data into training and test 30 times:
nTries <- 30
for ( iTry in 1:nTries ) {
bTrain <- sample(rep(c(TRUE,FALSE),length.out=nrow(CPUDat)))
# Try each method available in regsubsets
# to select best model of each size:
for ( jSelect in c("exhaustive", "backward", "forward", "seqrep") ) {
rsTrain <- regsubsets(PRP~.,CPUDat[bTrain,],nvmax=6,method=jSelect)
# Add up variable selections:
whichSum[,,jSelect] <- whichSum[,,jSelect] + summary(rsTrain)$which
# Calculate test error for each set of variables
# using predict.regsubsets implemented above:
for ( kVarSet in 1:6 ) {
# make predictions:
testPred <- predict(rsTrain,CPUDat[!bTrain,],id=kVarSet)
# calculate MSE:
mseTest <- mean((testPred-CPUDat[!bTrain,"PRP"])^2)
# add to data.frame for future plotting:
dfTmp <- rbind(dfTmp,data.frame(sim=iTry,sel=jSelect,vars=kVarSet,
mse=c(mseTest,summary(rsTrain)$rss[kVarSet]/sum(bTrain)),trainTest=c("test","train")))
}
}
}
mean(dfTmp$mse[vars == 3 && trainTest == "test"])
mean((CPUDat[!bTrain, "PRP"]-log(CPUDatRaw[names(CPUDatRaw)[!(names(CPUDatRaw) %in% c("vendor name","model name","ERP"))]]+1)[!bTrain, "ERP"]))
mean(dfTmp$mse[dfTmp$vars == 3 && dfTmp$trainTest == "test"])
mean((CPUDat[!bTrain, "PRP"]-log(CPUDatRaw[names(CPUDatRaw)[!(names(CPUDatRaw) %in% c("vendor name","model name","ERP"))]]+1)[!bTrain, "ERP"]))
mean(dfTmp$mse[dfTmp$vars == 3 && dfTmp$trainTest == "test"])
mean(dfTmp$mse[dfTmp$vars == 3 && dfTmp$trainTest == "test"])
dfTmp$mse[dfTmp$vars == 3 && dfTmp$trainTest == "test"]
dfTmp$trainTest == "test"
dfTmp$mse[dfTmp$vars == 3]
dfTmp$mse[dfTmp$vars == kVarSet]
dfTmp$vars == kVarSet
dfTmp$vars == 3 && dfTmp$trainTest == "test"
dfTmp$trainTest == "test"
dfTmp$vars == 3
dfTmp$trainTest == "test"
dfTmp$vars == 3
dfTmp$trainTest == "test"
dfTmp$vars == 3
dfTmp$vars == 3 && dfTmp$trainTest == "test"
(dfTmp$vars == 3) && (dfTmp$trainTest == "test")
(dfTmp$vars == 3) & (dfTmp$trainTest == "test")
mean(dfTmp$mse[vars == 3 & trainTest == "test"])
mean((CPUDat[!bTrain, "PRP"]-log(CPUDatRaw[names(CPUDatRaw)[!(names(CPUDatRaw) %in% c("vendor name","model name","ERP"))]]+1)[!bTrain, "ERP"]))
mean(dfTmp$mse[dfTmp$vars == 3 & dfTmp$trainTest == "test"])
mean((CPUDat[!bTrain, "PRP"]-log(CPUDatRaw[names(CPUDatRaw)[!(names(CPUDatRaw) %in% c("vendor name","model name","ERP"))]]+1)[!bTrain, "ERP"]))
mean((CPUDat[!bTrain, "PRP"]-log(CPUDatRaw[names(CPUDatRaw)[!(names(CPUDatRaw) %in% c("vendor name","model name","ERP"))]]+1)[!bTrain, "ERP"]))
mean(dfTmp$mse[dfTmp$vars == 3 & dfTmp$trainTest == "test"(CPUDat[!bTrain, "PRP"]-log(CPUDatRaw[names(CPUDatRaw)[!(names(CPUDatRaw) %in% c("vendor name","model name","ERP"))]]+1)[!bTrain, "ERP"]))
dfTmp$mse[dfTmp$vars == 3 & dfTmp$trainTest == "test"(CPUDat[!bTrain, "PRP"]-log(CPUDatRaw[names(CPUDatRaw)[!(names(CPUDatRaw) %in% c("vendor name","model name","ERP"))]]+1)[!bTrain, "ERP"])
)
dfTmp$mse[dfTmp$vars == 3 & dfTmp$trainTest == "test"(CPUDat[!bTrain, "PRP"]-log(CPUDatRaw[names(CPUDatRaw)[!(names(CPUDatRaw) %in% c("vendor name","model name","ERP"))]]+1)[!bTrain, "ERP"])
)
)
mean(dfTmp$mse[dfTmp$vars == 3 & dfTmp$trainTest == "test"(CPUDat[!bTrain, "PRP"]-log(CPUDatRaw[names(CPUDatRaw)[!(names(CPUDatRaw) %in% c("vendor name","model name","ERP"))]]+1)[!bTrain, "ERP"]))
(CPUDat[!bTrain, "PRP"]-log(CPUDatRaw[names(CPUDatRaw)[!(names(CPUDatRaw) %in% c("vendor name","model name","ERP"))]]+1)[!bTrain, "ERP"])
CPUDat[!bTrain, "PRP"]-log(CPUDatRaw[names(CPUDatRaw)[!(names(CPUDatRaw) %in% c("vendor name","model name","ERP"))]]+1)[!bTrain, "ERP"]
CPUDat[!bTrain, "PRP"]-log(CPUDatRaw[names(CPUDatRaw)[!(names(CPUDatRaw) %in% c("vendor name","model name","ERP"))]]+1)
mean(dfTmp$mse[dfTmp$vars == 3 & dfTmp$trainTest == "test"(CPUDat[!bTrain, "PRP"]-log(CPUDatRaw[names(CPUDatRaw)[!(names(CPUDatRaw) %in% c("vendor name","model name"))]]+1)[!bTrain, "ERP"]))
mean(dfTmp$mse[dfTmp$vars == 3 & dfTmp$trainTest == "test"(CPUDat[!bTrain, "PRP"]-log(CPUDatRaw[names(CPUDatRaw)[!(names(CPUDatRaw) %in% c("vendor name","model name"))]]+1)[!bTrain, "ERP"]))
mean(dfTmp$mse[dfTmp$vars == 3 & dfTmp$trainTest == "test"(CPUDat[!bTrain, "PRP"]-log(CPUDatRaw[names(CPUDatRaw)[!(names(CPUDatRaw) %in% c("vendor name","model name"))]]+1)[!bTrain, "ERP"])
)
mean(dfTmp$mse[dfTmp$vars == 3 & dfTmp$trainTest == "test"(CPUDat[!bTrain, "PRP"]-log(CPUDatRaw[names(CPUDatRaw)[!(names(CPUDatRaw) %in% c("vendor name","model name","ERP"))]]+1)[!bTrain, "ERP"]))
mean(dfTmp$mse[dfTmp$vars == 3 & dfTmp$trainTest == "test"(CPUDat[!bTrain, "PRP"]-log(CPUDatRaw[names(CPUDatRaw)[!(names(CPUDatRaw) %in% c("vendor name","model name"))]]+1)[!bTrain, "ERP"])
mean(dfTmp$mse[dfTmp$vars == 3 & dfTmp$trainTest == "test"(CPUDat[!bTrain, "PRP"]-log(CPUDatRaw[names(CPUDatRaw)[!(names(CPUDatRaw) %in% c("vendor name","model name","ERP"))]]+1)[!bTrain, "ERP"]))
mean((CPUDat[!bTrain, "PRP"]-log(CPUDatRaw[names(CPUDatRaw)[!(names(CPUDatRaw) %in% c("vendor name","model name","ERP"))]]+1)[!bTrain, "ERP"]))
mean((CPUDat[!bTrain, "PRP"]-log(CPUDatRaw[names(CPUDatRaw)[!(names(CPUDatRaw) %in% c("vendor name","model name"))]]+1)[!bTrain, "ERP"]))
# -1 to get rid of intercept that glmnet knows to include:
x <- model.matrix(PRP~.,CPUDat)[,-1]
head(CPUDat)
# notice how it created two columns for sex (first level is for intercept):
head(x)
y <- CPUDat[,"PRP"]
ridgeRes <- glmnet(x,y,alpha=0)
plot(ridgeRes)
dim(coef(ridgeRes))
coef(ridgeRes)
lassoCoefCnt <- 0
lassoMSE <- NULL
bTrain <- sample(rep(c(TRUE,FALSE),length.out=dim(x)[1]))
bTrain <- sample(rep(c(TRUE,FALSE),length.out=dim(x)[1]))
cvLassoTrain <- cv.glmnet(x[bTrain,],y[bTrain],alpha=1,lambda=10^((-120:0)/20))
lassoTrain <- glmnet(x[bTrain,],y[bTrain],alpha=1,lambda=10^((-120:0)/20))
lassoTrainCoef <- predict(lassoTrain,type="coefficients",s=cvLassoTrain$lambda.1se)
lassoCoefCnt <- lassoCoefCnt + (lassoTrainCoef[-1,1]!=0)
lassoTrainCoef
